# ğŸ“˜ RAG Backend â€” FastAPI + FAISS + BM25 + Re-Ranking + Gemini  

A production-ready Retrieval-Augmented Generation (RAG) backend that supports:  

- PDF upload  
- Text chunking  
- Embeddings using **E5-base-v2**  
- Semantic search (FAISS)  
- Keyword search (BM25)  
- Cross-encoder re-ranking  
- Context optimization  
- Gemini 2.5 Pro streaming responses  
- Docker deployment  
- Railway free hosting  

---

## ğŸš€ Features

### ğŸ” Hybrid Retrieval  
- **Semantic Search (FAISS + E5-base-v2)**  
- **Keyword Search (BM25)**  
- **Re-ranking using CrossEncoder (MS Marco MiniLM / TinyBERT)**  

### ğŸ§  LLM Integration  
- Uses **Gemini 2.5 Pro**  
- Fully supports **streaming responses**  
- Optimized context to reduce hallucination  

### ğŸ“„ PDF Support  
- Automatic chunking  
- Passage embeddings  
- Stored in FAISS + BM25 indexes  

### ğŸ³ Docker Ready  
- Fully containerized backend  
- Deployable to Railway, Render, or Fly.io  

---

## ğŸ“ Project Structure

```
rag-backend/
â”‚
â”œâ”€â”€ app.py                 # FastAPI main application
â”œâ”€â”€ Dockerfile             # Docker build file
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ embeddings.py      # E5-base embeddings (query + passage)
â”‚   â”œâ”€â”€ vector_store.py    # FAISS vector DB
â”‚   â”œâ”€â”€ bm25_store.py      # BM25 keyword index
â”‚   â”œâ”€â”€ reranker.py        # Cross-encoder re-ranking
â”‚   â”œâ”€â”€ rag.py             # Full RAG pipeline
â”‚
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ upload.py          # PDF upload + chunking
â”‚   â”œâ”€â”€ chat.py            # Chat endpoint (streaming)
â”‚
â””â”€â”€ ...
```

---

## âš™ï¸ Installation (Local Development)

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/pranil22/rag-backend.git
cd rag-backend
```

### 2ï¸âƒ£ Create a virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Create `.env` file

```
GEMINI_API_KEY=your_api_key_here
ENV=development
```

### 5ï¸âƒ£ Run FastAPI locally

```bash
uvicorn app:app --reload --port 8000
```

Open API docs:

ğŸ‘‰ http://localhost:8000/docs

---

## ğŸ³ Running with Docker

### 1ï¸âƒ£ Build the image

```bash
docker build -t rag-backend .
```

### 2ï¸âƒ£ Run the container with `.env`

```bash
docker run --env-file .env -p 8000:8000 rag-backend
```

Backend is now live at:

ğŸ‘‰ http://localhost:8000  
ğŸ‘‰ http://localhost:8000/docs

---

## ğŸš€ Deploy on Railway (Free)

### 1ï¸âƒ£ Push code to GitHub

```bash
git add .
git commit -m "deploy backend"
git push origin main
```

### 2ï¸âƒ£ Go to Railway â†’ **New Project â†’ Deploy from GitHub**

Railway automatically detects the `Dockerfile`.

### 3ï¸âƒ£ Add environment variables

```
GEMINI_API_KEY=your_key
ENV=production
```

### 4ï¸âƒ£ After deployment, Railway gives a URL:

```
https://<project>.up.railway.app
```

### 5ï¸âƒ£ Use this URL in your frontend

Example (React Vite `.env`):

```
VITE_API_BASE=https://<project>.up.railway.app
```

---

## ğŸ”Œ API Endpoints

### ğŸ“„ `/upload` â€” Upload PDF  
- Extracts text  
- Splits into chunks  
- Embeds each chunk  
- Saves into FAISS + BM25  
- Returns document ID  

### ğŸ’¬ `/chat` â€” RAG Chat (Streaming)
Steps:  
1. Query embedding (E5-base-v2)  
2. FAISS semantic search  
3. BM25 keyword search  
4. Merge candidates  
5. Cross-encoder re-ranking  
6. Build optimized context  
7. Gemini 2.5 Pro streaming answer  

---

## ğŸ”’ Environment Variables

| Variable | Description |
|---------|-------------|
| `GEMINI_API_KEY` | Gemini API key for LLM |
| `ENV` | development / production |

---

## ğŸ“¦ Requirements

```
fastapi
uvicorn[standard]
python-multipart
numpy
faiss-cpu
sentence-transformers
rank-bm25
google-generativeai
langchain
langchain-community
```

---

## ğŸ›  Troubleshooting

### âŒ FAISS dimension mismatch  
E5-base-v2 â†’ **768 dimensions**  
Ensure your FAISS index is initialized with:

```python
VectorStore(dim=768)
```

### âŒ Streaming not working  
Railway supports streaming â€” ensure frontend uses ReadableStream.

### âŒ FAISS index resets on restart  
Enable Railway **Volumes** and store:  
- `index.faiss`  
- `chunks.json`

---

## ğŸ“œ License

MIT License â€” free to use, modify, distribute.

---

## ğŸ¤ Contributing

PRs and issues are welcome!

---

## ğŸ™Œ Credits

Built using:  
FastAPI â€¢ FAISS â€¢ BM25 â€¢ E5 Embeddings â€¢ CrossEncoders â€¢ Gemini API â€¢ Docker â€¢ Railway  
